{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joeljohnston/pyforml/blob/main/Week_4_Unsupervised_Learning_and_Classification_with_Scikit_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2040e3d-bfb8-40b8-8861-4485db413cf7",
      "metadata": {
        "id": "a2040e3d-bfb8-40b8-8861-4485db413cf7"
      },
      "source": [
        "> 1. DUPLICATE THIS COLAB DOCUMENT TO START WORKING ON IT: On the top-left corner of this page, go to File > Save a copy to drive.\n",
        "> 2. SHARE SETTINGS: In the new notebook, set the sharing settings to \"Anyone with the link\" by clicking \"Share\" on the top-right corner.\n",
        "\n",
        "<center>\n",
        "  <img src=https://www.freevector.com/uploads/vector/preview/31087/07Januari2021-06_generated.jpg width=\"500\" align=\"center\" />\n",
        "</center>\n",
        "<br/>\n",
        "\n",
        "\n",
        "# Week 4: (Un)Supervised Predictions for Airbnb listings!\n",
        "\n",
        "This is the fourth and last week's project üò¢ of *Python for Machine Learning*. Here we are going to put everything we've learned over the last three weeks together and create yet another exciting algorithm that we can then use for creating a Streamlit App!\n",
        "\n",
        "We'll first start using unsupervised learning, and with that information we are going to make a supervised model. All by using Pipelines, ColumnTransformers, Plotly and some other parts! Let's do it üí™üí™!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the Dataset\n",
        "\n",
        "You'll need to download some prerequisite Python packages in order to run all the code below. Let's install them!"
      ],
      "metadata": {
        "id": "rISRrL2X93Yx"
      },
      "id": "rISRrL2X93Yx"
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install numpy streamlit pandas==1.5.2 scikit-learn==1.2.0"
      ],
      "metadata": {
        "id": "JspZZKEj9ytH"
      },
      "id": "JspZZKEj9ytH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0c21b1ad-25c8-4a99-a4e0-764d568f711b",
      "metadata": {
        "id": "0c21b1ad-25c8-4a99-a4e0-764d568f711b"
      },
      "source": [
        "We will download the datasets from Google Drive just like we did the previous weeks using the [Pickle](https://pythonnumericalmethods.berkeley.edu/notebooks/chapter11.03-Pickle-Files.html) format."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1KTF77Sj0kWyft9gNT3_6k84gauPA95rG' -O listings.pkl"
      ],
      "metadata": {
        "id": "jN2Z9s_jkJjd"
      },
      "id": "jN2Z9s_jkJjd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Show all columns (instead of cascading columns in the middle)\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "# Don't show numbers in scientific notation\n",
        "pd.set_option(\"display.float_format\", \"{:.2f}\".format)"
      ],
      "metadata": {
        "id": "IC0UndnWK9M1"
      },
      "id": "IC0UndnWK9M1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting seed allows us to generate a random dataset split and\n",
        "# algorithms that are the same on every computer. Otherwise,\n",
        "# every time you run the split, you'd get a different dataset split.\n",
        "SEED = 42"
      ],
      "metadata": {
        "id": "ax73vOWcgkfM"
      },
      "id": "ax73vOWcgkfM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing the Dataset\n",
        "Please load the downloaded file as a DataFrame (df). The method for loading these datasets is the same as what we did on the Uplimit platform."
      ],
      "metadata": {
        "id": "RNofYa-GU8D2"
      },
      "id": "RNofYa-GU8D2"
    },
    {
      "cell_type": "markdown",
      "id": "4511c023-4bc6-4399-b5bf-c4977fdf1ea0",
      "metadata": {
        "id": "4511c023-4bc6-4399-b5bf-c4977fdf1ea0"
      },
      "source": [
        "#### Task 1: Read Pickle\n",
        "\n",
        "\n",
        "Read the Python Pickle file we've just downloaded as `df_list`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read a Python Pickle file\n",
        "df_list = ... # ADD YOUR CODE HERE"
      ],
      "metadata": {
        "id": "-nEH0subOtug"
      },
      "id": "-nEH0subOtug",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "df_list = pd.read_pickle(\"listings.pkl\")\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "Hg4BjXRjOcII"
      },
      "id": "Hg4BjXRjOcII"
    },
    {
      "cell_type": "markdown",
      "id": "3f375704-9648-49cc-a6fc-a7f7208b476f",
      "metadata": {
        "tags": [],
        "id": "3f375704-9648-49cc-a6fc-a7f7208b476f"
      },
      "source": [
        "Now let's have a look at the **Listings DataFrame** and see what kinds of datapoints there are in the dataset. Show the first 2 rows."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show first two rows of the dataset\n",
        "... # ADD YOUR CODE HERE"
      ],
      "metadata": {
        "id": "JaHn5P0_O3qT"
      },
      "id": "JaHn5P0_O3qT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "df_list.head(2)\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "zT7wuJ1KOx-7"
      },
      "id": "zT7wuJ1KOx-7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Awesome, just like last week, our next step is to get an overview of the columns that are in this particular DataFrame üßê."
      ],
      "metadata": {
        "id": "cP2eVhs0L0Gq"
      },
      "id": "cP2eVhs0L0Gq"
    },
    {
      "cell_type": "markdown",
      "id": "38b21f27-24ea-4622-8c2a-c4bb065b5d4e",
      "metadata": {
        "id": "38b21f27-24ea-4622-8c2a-c4bb065b5d4e"
      },
      "source": [
        "#### Task 2: Print column names, types, and non-null values\n",
        "\n",
        "Let's try and get an overview of the **Listings DataFrame**, called `df_list` with the [`info()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html)-command. This should show us some details about the columns in the DataFrame, like the column names, their data types, and the number of non-null values."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "... # ADD YOUR CODE HERE"
      ],
      "metadata": {
        "id": "fy0TfpzJO9NE"
      },
      "id": "fy0TfpzJO9NE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_list.info()"
      ],
      "metadata": {
        "id": "wOKwdo8gH9Th"
      },
      "id": "wOKwdo8gH9Th",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "df_list.info()\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "HKTyyRvfO8ZM"
      },
      "id": "HKTyyRvfO8ZM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like last week we have a lot of attributes, of which a few we will drop. Some require processing while others don't. For example columns with the dtype **category** and **boolean** require some processing so that it can be used by Scikit-learn algorithms since most of these algorithms work best with numerical values."
      ],
      "metadata": {
        "id": "4ml13_W2eKvm"
      },
      "id": "4ml13_W2eKvm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 3: Make a selection\n",
        "\n",
        "There are a total of 17 columns. For readability purposes we are going to prematurely drop a lot of these columns. In practice you often drop columns at a later stage once you've determined their value. This is something we'll look into next week. For now we want you to drop the columns:\n",
        "\n",
        "- id (it has no meaning for the ML algorithm)\n",
        "- discount_per_5_days_booked\n",
        "- discount_per_10_days_booked\n",
        "- discount_per_30_and_more_days_booked"
      ],
      "metadata": {
        "id": "fM5DSYBMP6ZV"
      },
      "id": "fM5DSYBMP6ZV"
    },
    {
      "cell_type": "code",
      "source": [
        "df_list = ... # ADD YOUR CODE HERE"
      ],
      "metadata": {
        "id": "RWjB_nvCO_Me"
      },
      "id": "RWjB_nvCO_Me",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "df_list_copy = df_list.drop(columns=['id', 'discount_per_5_days_booked',\n",
        "                                     'discount_per_10_days_booked', 'discount_per_30_and_more_days_booked'])\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "Wq-cIUOAPY1b"
      },
      "id": "Wq-cIUOAPY1b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look at the leftover information contained in the dataframe again."
      ],
      "metadata": {
        "id": "v_h9DU2PjkVe"
      },
      "id": "v_h9DU2PjkVe"
    },
    {
      "cell_type": "code",
      "source": [
        "... # ADD YOUR CODE HERE"
      ],
      "metadata": {
        "id": "FPyNu16IPA-r"
      },
      "id": "FPyNu16IPA-r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "df_list.info()\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "stZz4J3APtbQ"
      },
      "id": "stZz4J3APtbQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are left with 3 boolean values and 3 categorical values, which need to be encoded.\n",
        "\n",
        "Now to determine our target variable, we have **no** labels assigned to this target variable; which is the combination of \"price_in_dollar\" and \"host_reported_average_tip\".\n",
        "\n",
        "Just like we saw on this weeks content, we want to first cluster these two numerical values into a few groups. This creates a new categorical variable called **listing_tipping_group**, which will be used as our target for the algorithm that we are going to make.\n",
        "\n"
      ],
      "metadata": {
        "id": "0DYmBpKtkOVN"
      },
      "id": "0DYmBpKtkOVN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 4: Visualize the two numerical variables\n",
        "\n",
        "Create a scatter plot displaying the two numerical variables: \"price_in_dollar\" and \"host_reported_average_tip\"."
      ],
      "metadata": {
        "id": "a1qLOXOjV_tw"
      },
      "id": "a1qLOXOjV_tw"
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = ... # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "wTiQHBsxVBAH"
      },
      "id": "wTiQHBsxVBAH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter(df_list, x=\"price_in_dollar\", y=\"host_reported_average_tip\")\n",
        "fig.show()\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "8RBWziuASbI5"
      },
      "id": "8RBWziuASbI5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 5: Define Three clusters via K-Means\n",
        "\n",
        "Just like in the unsupervised Section of Uplimit we are going to use the columns **price_in_dollar** and **host_reported_average_tip** to create a cluster variable. This we'll use later on! Let's start by importing the Kmeans, Pipeline and MinMaxScaler"
      ],
      "metadata": {
        "id": "8CYBS6_kZklh"
      },
      "id": "8CYBS6_kZklh"
    },
    {
      "cell_type": "code",
      "source": [
        "... # YOUR 3 IMPORTS HERE"
      ],
      "metadata": {
        "id": "SZMT3CGUhV0c"
      },
      "id": "SZMT3CGUhV0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "_qBiCyFFSkkW"
      },
      "id": "_qBiCyFFSkkW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we want to create a pipeline which integrates the scaler and KMeans algorithm. Then we use fit_predict to create the KMean labels.\n",
        "\n",
        "*Make sure to set a seed for your algorithm/model.*"
      ],
      "metadata": {
        "id": "9hKe9397hWRa"
      },
      "id": "9hKe9397hWRa"
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ... , # YOUR CODE HERE\n",
        "    ... # YOUR CODE HERE\n",
        "    ])\n",
        "\n",
        "Kmean_labels = pipeline.fit_predict(\n",
        "    df_list[[\"price_in_dollar\", \"host_reported_average_tip\"]]\n",
        ")"
      ],
      "metadata": {
        "id": "WV77QCjGVA7W"
      },
      "id": "WV77QCjGVA7W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", MinMaxScaler()),\n",
        "    (\"model\", KMeans(n_clusters=3, random_state=SEED))\n",
        "    ])\n",
        "\n",
        "Kmean_labels = pipeline.fit_predict(\n",
        "    df_list[[\"price_in_dollar\", \"host_reported_average_tip\"]]\n",
        ")\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "1HxEesA-Stvz"
      },
      "id": "1HxEesA-Stvz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now since these labels are seen as numerical, when visualizing they will be regarded as numerical/continuous variables. However, these labels indicate three separate groups, meaning we want to change it into a categorical variable. For now we'll want you to convert these numerical labels into string variables."
      ],
      "metadata": {
        "id": "lwS0lLBug_Rk"
      },
      "id": "lwS0lLBug_Rk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the labels from numerical into categorical.\n",
        "Kmean_labels = ... # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "YSP0vOl0hA-m"
      },
      "id": "YSP0vOl0hA-m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Kmean_labels"
      ],
      "metadata": {
        "id": "fa6wXAUyjx3_"
      },
      "id": "fa6wXAUyjx3_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "Kmean_labels = [str(x) for x in Kmean_labels]\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "9ldnK_PES20E"
      },
      "id": "9ldnK_PES20E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, as a last check, let's confirm the labels were assigned as expected, by visualizing the scatterplot with the labels!"
      ],
      "metadata": {
        "id": "BYDFDPtyg-_B"
      },
      "id": "BYDFDPtyg-_B"
    },
    {
      "cell_type": "code",
      "source": [
        "fig = ... # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "TVlJ3JdKhBjZ"
      },
      "id": "TVlJ3JdKhBjZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "fig = px.scatter(\n",
        "    df_list, x=\"price_in_dollar\", y=\"host_reported_average_tip\", color=Kmean_labels\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "sx4DVfbUS_n8"
      },
      "id": "sx4DVfbUS_n8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 6: Reassign as a new column to the Dataset\n",
        "\n",
        "\n",
        "Let's add this list as a column to our dataset **df_list** using the name **listing_tipping_group**."
      ],
      "metadata": {
        "id": "ySBsjR3baGZ1"
      },
      "id": "ySBsjR3baGZ1"
    },
    {
      "cell_type": "code",
      "source": [
        "... # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "oVboBZZUZzbn"
      },
      "id": "oVboBZZUZzbn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Kmean_labels"
      ],
      "metadata": {
        "id": "_TbpSiPaiWfc"
      },
      "id": "_TbpSiPaiWfc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "df_list[\"listing_tipping_group\"] = Kmean_labels\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "PaFqVgC3TNmV"
      },
      "id": "PaFqVgC3TNmV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 7: Manually split up Three into Four clusters\n",
        "\n",
        "\n",
        "As you might've noticed, there are also listings that receive no tips at all. We want to recognize these listings as a separate group. Let's use Pandas for that to overwrite labels which have received no tips to the number 3."
      ],
      "metadata": {
        "id": "syM3H3c8Z0AL"
      },
      "id": "syM3H3c8Z0AL"
    },
    {
      "cell_type": "code",
      "source": [
        "df_list.loc[ ... ] = ... # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "neoxPM2QVA0Z"
      },
      "id": "neoxPM2QVA0Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "df_list.loc[df_list[\"host_reported_average_tip\"] == 0.00, \"listing_tipping_group\"] = \"3\"\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "Qn9rvA97TaKL"
      },
      "id": "Qn9rvA97TaKL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make our labels a bit more \"expressive\", let's use a [`replace()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html) operation to make the values like:\n",
        "\n",
        "- \"0\" to \"average tip\"\n",
        "- \"1\" to \"high tip\"\n",
        "- \"2\" to \"low tip\"\n",
        "- \"3\" to \"no tip\"\n"
      ],
      "metadata": {
        "id": "lJqVlKz_kx2f"
      },
      "id": "lJqVlKz_kx2f"
    },
    {
      "cell_type": "code",
      "source": [
        "df_list[\"listing_tipping_group\"] = ... # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "5pRME2tSkxq9"
      },
      "id": "5pRME2tSkxq9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "df_list[\"listing_tipping_group\"] = df_list[\"listing_tipping_group\"].replace({\"0\": \"average tip\", \"1\": \"high tip\", \"2\": \"low tip\", \"3\": \"no tip\"})\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "GViulRfGTsm4"
      },
      "id": "GViulRfGTsm4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Awesome, now let's encode these labels back into numbers, haha! You might think why did we do it in the first place? Well, the Scikit-learn encoder has a way to easily transform these labels back and forth between numbers and label names. So when we need labels, we just turn it back using a Scikit-learn function, which is easier than constantly having to replace values, like we did above (or remembering what the values meant)."
      ],
      "metadata": {
        "id": "Mimyr6L_l_Lo"
      },
      "id": "Mimyr6L_l_Lo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 8: Encode our Label\n",
        "\n",
        "For the model/algorithm that we are building, we use the **listing_tipping_group** as our target ($y$) label. Let's assign this column as our *y* variable and encode it with a [`LabelEncoder()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
      ],
      "metadata": {
        "id": "8gzIdMIQbrU7"
      },
      "id": "8gzIdMIQbrU7"
    },
    {
      "cell_type": "code",
      "source": [
        "y = ... # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "YysQRzbubdfI"
      },
      "id": "YysQRzbubdfI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "y = df_list[\"listing_tipping_group\"]\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "2nMCfMC-T6Le"
      },
      "id": "2nMCfMC-T6Le"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's encode it! Make sure to use ravel."
      ],
      "metadata": {
        "id": "sGeIPKv4oX53"
      },
      "id": "sGeIPKv4oX53"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import ravel  # change column-vector to 1d-array\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_enc = LabelEncoder()\n",
        "y = ... # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "QvaATIIpoXSN"
      },
      "id": "QvaATIIpoXSN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from numpy import ravel  # change column-vector to 1d-array\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_enc = LabelEncoder()\n",
        "y = label_enc.fit_transform(ravel(y))\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "F3r_b52aUDze"
      },
      "id": "F3r_b52aUDze"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try and changing back one of the encoded labels by using [`inverse_transform`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder.inverse_transform). Input a value between 0 to 3 and see what comes back.\n",
        "\n",
        "*You might notice that the numbers don't coincide with what the numbers originally were when we generated the three clusters, this is okay and shouldn't influence our results*"
      ],
      "metadata": {
        "id": "HgLDwo-IogVD"
      },
      "id": "HgLDwo-IogVD"
    },
    {
      "cell_type": "code",
      "source": [
        "label_enc.inverse_transform(np.array([0]))"
      ],
      "metadata": {
        "id": "UFAneZhjofEl"
      },
      "id": "UFAneZhjofEl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 9: Set Booleans to Int\n",
        "\n",
        "Taking a closer look at our dataset, reveals that we have three columns that are boolean, which we want to convert to integer."
      ],
      "metadata": {
        "id": "DkarfKyFbTZt"
      },
      "id": "DkarfKyFbTZt"
    },
    {
      "cell_type": "code",
      "source": [
        "list(df_list.select_dtypes(include=[\"bool\"]).columns)"
      ],
      "metadata": {
        "id": "yXrPaEipbsGb"
      },
      "id": "yXrPaEipbsGb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's go ahead and convert it into int!"
      ],
      "metadata": {
        "id": "kRRlOts2soH1"
      },
      "id": "kRRlOts2soH1"
    },
    {
      "cell_type": "code",
      "source": [
        "... # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "JlqwqyYgsn6Y"
      },
      "id": "JlqwqyYgsn6Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "df_list[\"host_is_superhost\"] = df_list[\"host_is_superhost\"].astype(int)\n",
        "df_list[\"has_availability\"] = df_list[\"has_availability\"].astype(int)\n",
        "df_list[\"instant_bookable\"] = df_list[\"instant_bookable\"].astype(int)\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "yK-DXDcOUvob"
      },
      "id": "yK-DXDcOUvob"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 10: Split our Dataset\n",
        "\n",
        "\n",
        "Before we split our dataset we drop **price_in_dollar** and **host_reported_average_tip** since these were used to create **listing_tipping_group**."
      ],
      "metadata": {
        "id": "sF6hjGS7aP7Q"
      },
      "id": "sF6hjGS7aP7Q"
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = (\n",
        "    ... , # YOUR CODE HERE\n",
        "    ... # YOUR CODE HERE\n",
        ")"
      ],
      "metadata": {
        "id": "LMFBCVidaPYh"
      },
      "id": "LMFBCVidaPYh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "X, y = (\n",
        "    df_list[[\"host_acceptance_rate\", \"host_is_superhost\",\n",
        "             \"has_availability\", \"number_of_reviews_l30d\",\n",
        "             \"neighbourhood\", \"room_type\",\n",
        "             \"accommodates\", \"review_scores_rating\",\n",
        "             \"instant_bookable\", \"service_cost\"]],\n",
        "        df_list[[\"listing_tipping_group\"]]\n",
        "        )\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "fX5ypWVAU-5A"
      },
      "id": "fX5ypWVAU-5A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now that we split up the dataset into X and y, let's split it also up into training, validation and test set."
      ],
      "metadata": {
        "id": "oquiXp8vt6Pe"
      },
      "id": "oquiXp8vt6Pe"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_validation_test_split(\n",
        "    X, y, train_ratio: float, validation_ratio: float, test_ratio: float\n",
        "):\n",
        "    # Split up dataset into train and test, of which we split up the test.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=(1 - train_ratio), random_state=SEED\n",
        "    )\n",
        "\n",
        "    # Split up test into two (validation and test).\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_test,\n",
        "        y_test,\n",
        "        test_size=(test_ratio / (test_ratio + validation_ratio)),\n",
        "        random_state=SEED,\n",
        "    )\n",
        "\n",
        "    # Return the splits\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "\n",
        "# Splits according to ratio of 80/10/10\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_validation_test_split(\n",
        "    X, y, 0.75, 0.15, 0.1\n",
        ")"
      ],
      "metadata": {
        "id": "ZlyNjnMPt6FZ"
      },
      "id": "ZlyNjnMPt6FZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 11: Encode the Numerical Variables\n",
        "\n",
        "Now the real interesting part starts where we turn the different numerical variable ranges to the same scale (From 0 to 1) by using a [`MinMaxScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html). This way, algorithms that are sensitive to scale will not regard some features more important than others, purely because of a scale that was initially much bigger.\n",
        "\n",
        "So let's prepare a pipeline for the numerical columns!"
      ],
      "metadata": {
        "id": "nSLIwYcCbgFB"
      },
      "id": "nSLIwYcCbgFB"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Select the numerical columns\n",
        "numerical_cols_X = ... # YOUR CODE HERE\n",
        "\n",
        "# Numerical pipeline\n",
        "num_pipeline = Pipeline([\n",
        "    ... # YOUR CODE HERE\n",
        "])"
      ],
      "metadata": {
        "id": "Gm6caBe6Z_wq"
      },
      "id": "Gm6caBe6Z_wq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Select the numerical columns\n",
        "numerical_cols_X = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "\n",
        "# Numerical pipeline\n",
        "num_pipeline = Pipeline([\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "9wqFBrc4VJ_3"
      },
      "id": "9wqFBrc4VJ_3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 12: Encode the Categorical Variables\n",
        "\n",
        "\n",
        "Now, categorical variables often don't need scaling but they do need proper encoding. For this we'll use [`OneHotEncoder()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) to achieve that.\n",
        "\n",
        "Make such a pipeline!"
      ],
      "metadata": {
        "id": "6i8mOqbRcKZA"
      },
      "id": "6i8mOqbRcKZA"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Select the categorical columns\n",
        "categorical_cols_X = ... # YOUR CODE HERE\n",
        "\n",
        "# Categorical pipeline: containing only one encoder\n",
        "cat_pipeline = Pipeline([\n",
        "    ... # YOUR CODE HERE\n",
        "])"
      ],
      "metadata": {
        "id": "EHHniYnXcJ5U"
      },
      "id": "EHHniYnXcJ5U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Select the categorical columns\n",
        "categorical_cols_X = X_train.select_dtypes(include=[\"category\"]).columns\n",
        "\n",
        "# Categorical pipeline: containing only one encoder\n",
        "cat_pipeline = Pipeline([\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
        "])\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "ipLfEHlDVd-r"
      },
      "id": "ipLfEHlDVd-r"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 13: Combine the Pipelines in ColumnTransformer\n",
        "\n",
        "Let's put the ColumnTransformer to good use and combine our two pipelines into one variable called *preprocessor*."
      ],
      "metadata": {
        "id": "yFQUdrjUyy1u"
      },
      "id": "yFQUdrjUyy1u"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Combine the two pipelines into one ColumnTransformer\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', ..., ...),  # Notify Transformer which cols to use.\n",
        "    ('num', ..., ...)  # Notify Transformer which cols to use.\n",
        "])"
      ],
      "metadata": {
        "id": "SS2unsysyyqw"
      },
      "id": "SS2unsysyyqw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Combine the two pipelines into one ColumnTransformer\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', cat_pipeline, categorical_cols_X),  # Notify Transformer which cols to use.\n",
        "    ('num', num_pipeline, numerical_cols_X)  # Notify Transformer which cols to use.\n",
        "])\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "0PZDcmRjWKPC"
      },
      "id": "0PZDcmRjWKPC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 14: Select our Model\n",
        "\n",
        "In this week's project we are going to be using a [SVM classifier](https://youtu.be/_YPScrckx28) to make predictions! The implementation is called [`SVC()`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) and with pipelines is just as simple as plugging in other models.\n",
        "\n",
        "*Make sure to set the seed of the SVM/SVC algorithm/model.*"
      ],
      "metadata": {
        "id": "-b5o5X0DcSXe"
      },
      "id": "-b5o5X0DcSXe"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Combine the preprocesser with the Algorithm/model\n",
        "pipeline = Pipeline([\n",
        "    ... , # YOUR CODE HERE\n",
        "    ... # YOUR CODE HERE\n",
        "    )\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "ASCMurpFZ_q7"
      },
      "id": "ASCMurpFZ_q7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Combine the preprocesser with the Algorithm/model\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', SVC(random_state=SEED)\n",
        "    )\n",
        "])\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "WSRSQTFgWRkB"
      },
      "id": "WSRSQTFgWRkB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 15: Train the Model\n"
      ],
      "metadata": {
        "id": "hOm-iAxAwux4"
      },
      "id": "hOm-iAxAwux4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the final pipeline on the training set.\n",
        "... # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "dFJ5AymEwv9U"
      },
      "id": "dFJ5AymEwv9U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "JrorH6DGWgA5"
      },
      "id": "JrorH6DGWgA5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 16: Measure our Performance\n",
        "\n",
        "\n",
        "During the course we've mentioned a few times there are more metrics. In this case let's use another such metric, [F1](https://towardsdatascience.com/the-f1-score-bec2bbc38aa6)! It is commonly used for Classification and therefore, let's try and implement [`f1_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)!\n",
        "\n",
        "*Set the parameter `average=\"macro\"` since for the `f1_score()` we have more than two classes that we are trying to predict (4).*"
      ],
      "metadata": {
        "id": "mbbn11SdcqP4"
      },
      "id": "mbbn11SdcqP4"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Do a \"trial exam\" using the validation set.\n",
        "y_predict = ... # YOUR CODE HERE\n",
        "\n",
        "# Compare algorithms' \"trial exam\" vs. expected.\n",
        "f1_score( ... ).round(4) # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "mrO7owjlZ_lq"
      },
      "id": "mrO7owjlZ_lq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Do a \"trial exam\" using the validation set.\n",
        "y_predict = pipeline.predict(X_val)\n",
        "\n",
        "# Compare algorithms' \"trial exam\" vs. expected.\n",
        "f1_score(y_val, y_predict, average=\"macro\").round(4)\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "LBHX1VM3WoE7"
      },
      "id": "LBHX1VM3WoE7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#### (Optional) Task 17: Confusion Matrix\n",
        "\n",
        "The confusion matrix is a great chart to visually capture how your model is performing. It shows you which labels were expected, and how they were actually predicted. The confusion matrix of the previous model reveals that:\n",
        "\n",
        "- The diagonal are correctly predicted labels, which for the majority seems right\n",
        "- 7 average tips were incorrectly identified to be high tip\n",
        "- 21 average tips were incorrectly identified to be low tip\n",
        "- 59 high tips were incorrectly identified to be average tip\n",
        "- 24 low tips were incorrectly identified as average tip\n",
        "- 6 no tips were incorrectly identified as average tip\n",
        "- 1 no tips were incorrectly identified as high tip\n",
        "- 4 no tips were incorrectly identified as low tip\n",
        "- sum up a row horizontally provides you with sum **actual** total of the class\n",
        "- sum up a row vertically provides you with a sum of **predicted** total of the class\n",
        "\n",
        "[This video](https://youtu.be/Kdsp6soqA7o?t=24) also clearly explains how to interpret it."
      ],
      "metadata": {
        "id": "uyA-8Ab_0SLN"
      },
      "id": "uyA-8Ab_0SLN"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import plotly.express as px\n",
        "\n",
        "conf_mat = confusion_matrix(y_val, y_predict, labels=pipeline[\"model\"].classes_)\n",
        "\n",
        "fig = px.imshow(conf_mat,\n",
        "                labels=dict(x=\"Predicted Label\", y=\"True Label\"),\n",
        "                x=pipeline[\"model\"].classes_,\n",
        "                y=pipeline[\"model\"].classes_,\n",
        "                text_auto=True)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "YkxPeNyA1pLa"
      },
      "id": "YkxPeNyA1pLa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (Optional) Task 18: Example prediction\n",
        "\n",
        "Now, just like last week, let's retrain our model, to only use a few features. In this case we'll go with 4 features. This model we'll use to predict in which tip bracket we fit and is used to make another Streamlit app with!\n",
        "\n",
        "Make a selection of these features for X_train and X_val:\n",
        "- \"review_scores_rating\"\n",
        "- \"room_type\"\n",
        "- \"service_cost\"\n",
        "- \"instant_bookable\""
      ],
      "metadata": {
        "id": "vIBePV2WHVCF"
      },
      "id": "vIBePV2WHVCF"
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import ravel  # change column-vector to 1d-array\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "X_train = ... # YOUR CODE HERE\n",
        "X_val = ... # YOUR CODE HERE\n",
        "\n",
        "# Select the categorical columns\n",
        "categorical_cols_X = X_train.select_dtypes(include=[\"category\"]).columns\n",
        "numerical_cols_X = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "\n",
        "# Categorical pipeline: containing only one encoder\n",
        "cat_pipeline = Pipeline([\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "# Numerical pipeline: containing only one encoder\n",
        "num_pipeline = Pipeline([\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "# Combine the two pipelines into one ColumnTransformer\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', cat_pipeline, categorical_cols_X),\n",
        "    ('num', num_pipeline, numerical_cols_X)\n",
        "])\n",
        "\n",
        "# Combine the preprocesser with the Algorithm/model\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', SVC(random_state=SEED))\n",
        "])\n",
        "\n",
        "# Train the final pipeline on the training set.\n",
        "pipeline.fit(X_train, ravel(y_train))"
      ],
      "metadata": {
        "id": "Br_pSFLjF5kA"
      },
      "id": "Br_pSFLjF5kA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "from numpy import ravel  # change column-vector to 1d-array\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "X_train = X_train[[\"review_scores_rating\", \"room_type\", \"service_cost\", \"instant_bookable\"]]\n",
        "X_val = X_val[[\"review_scores_rating\", \"room_type\", \"service_cost\", \"instant_bookable\"]]\n",
        "\n",
        "# Select the categorical columns\n",
        "categorical_cols_X = X_train.select_dtypes(include=[\"category\"]).columns\n",
        "numerical_cols_X = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "\n",
        "# Categorical pipeline: containing only one encoder\n",
        "cat_pipeline = Pipeline([\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "# Numerical pipeline: containing only one encoder\n",
        "num_pipeline = Pipeline([\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "# Combine the two pipelines into one ColumnTransformer\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', cat_pipeline, categorical_cols_X),\n",
        "    ('num', num_pipeline, numerical_cols_X)\n",
        "])\n",
        "\n",
        "# Combine the preprocesser with the Algorithm/model\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', SVC(random_state=SEED))\n",
        "])\n",
        "\n",
        "# Train the final pipeline on the training set.\n",
        "pipeline.fit(X_train, ravel(y_train))\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "dD5A-KaPW9qj"
      },
      "id": "dD5A-KaPW9qj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's run it fully, using the pipeline and observing the f1_score."
      ],
      "metadata": {
        "id": "FpA1y4lHFfd_"
      },
      "id": "FpA1y4lHFfd_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Do a \"trial exam\" using the validation set.\n",
        "y_predict = ... # YOUR CODE HERE\n",
        "\n",
        "# Compare algorithms' \"trial exam\" vs. expected.\n",
        "f1_score( ... ).round(4) # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "H9_V0SESFTWE"
      },
      "id": "H9_V0SESFTWE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Show Solution</summary>\n",
        "\n",
        "```python\n",
        "# Do a \"trial exam\" using the validation set.\n",
        "y_predict = pipeline.predict(X_val)\n",
        "\n",
        "# Compare algorithms' \"trial exam\" vs. expected.\n",
        "f1_score(y_val, y_predict, average=\"macro\").round(4)\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "oqf2GIvhXHSZ"
      },
      "id": "oqf2GIvhXHSZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the metric performance has decreased, we were able to distill the number of features to only 4. Now let's try and see if we can predict a new listings' expected average tip."
      ],
      "metadata": {
        "id": "RS5S5qZl8b6J"
      },
      "id": "RS5S5qZl8b6J"
    },
    {
      "cell_type": "code",
      "source": [
        "# review_scores_rating: 0 to 5\n",
        "# room_type: ['Shared room', 'Private room', 'Hotel room', 'Entire home/apt']\n",
        "# service_cost: ['$0.99', '$4.99', '$2.99', '$10.99']\n",
        "# instant_bookable: 0, 1\n",
        "example = pd.DataFrame({\n",
        "    \"review_scores_rating\": [0.50],\n",
        "    \"room_type\": [\"Shared room\"],\n",
        "    \"service_cost\": [\"$0.99\"],\n",
        "    \"instant_bookable\": [0]\n",
        "    })\n",
        "\n",
        "pipeline.predict(example)[0]"
      ],
      "metadata": {
        "id": "nLDyQrDdlRcj"
      },
      "id": "nLDyQrDdlRcj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Awesome! Today you've made a Machine Learning project, using Numpy, Pandas, Plotly and Scikit-Learn to create predictions given the Airbnb dataset! This is a simplified version of a professional workflow and is often how companies start, by first doing the bare minimum and then keep expanding the complexity of the model. That way you can have something working quickly, and improve steadily with a very quick feedback loop!\n",
        "\n",
        "Now as an extra we'll explore how to deploy this model as a Streamlit app!"
      ],
      "metadata": {
        "id": "SWpIjbkiKvcj"
      },
      "id": "SWpIjbkiKvcj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional) Make an App for Your Portfolio!\n",
        "\n",
        "<center>\n",
        "  <img src=https://griddb-pro.azureedge.net/en/wp-content/uploads/2021/08/streamlit-1160x650.png width=\"500\" align=\"center\" />\n",
        "</center>\n",
        "<br/>\n",
        "\n",
        "**Participants such as yourselves often want to use the weekly Uplimit projects for their portfolios. To facilitate that, we've created this section. It might seem like a lot, but it's actually just following instructions and copy-pasting. Reach out on Slack if you get stuck!**\n",
        "\n",
        "You will make an app that uses the model you just created, encapsulates that in a neat Streamlit interface, where you can provide input through the use of sliders!\n",
        "\n",
        "<center>\n",
        "  <img src=https://corise-ugc.com/static/course/intermediate-python-for-data-science/assets/clgawo8po03cx12d029tbha5c/Screenshot%202023-04-10%20150104.png width=\"500\" align=\"center\" />\n",
        "</center>\n",
        "<br/>\n",
        "\n",
        "To visualize this, we will again use a library called [Streamlit](https://streamlit.io/). For now you are not expected to know how Streamlit works, but you are expected to be able to copy-paste and follow instructions if you want to share this project as part of your portfolio!\n",
        "\n",
        "We are going to use [Streamlit Share](https://share.streamlit.io/) to host your projects. It's a website that allows us to host our interactive projects for free online! Again, we don't expect you to understand how to use and/or modify the code we will show below. We do expect you to read the instructions and copy-paste our code to the Streamlit Share platform. Feel free to change it any way you like. Some great starting points are [here](https://python.plainenglish.io/how-to-build-web-app-using-streamlit-pandas-numpy-5e134f0cf552), [here](https://docs.streamlit.io/library/get-started/create-an-app), [here](https://streamlit.io/components), and [here](https://streamlit.io/gallery)!"
      ],
      "metadata": {
        "id": "PvhgbGXiLVTc"
      },
      "id": "PvhgbGXiLVTc"
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# rename our pipeline to model\n",
        "model = pipeline\n",
        "\n",
        "# Dump our model\n",
        "pickle.dump(pipeline, open(\"model.pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "4AVyiZlPvLcZ"
      },
      "id": "4AVyiZlPvLcZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the file locally\n",
        "files.download('model.pkl')"
      ],
      "metadata": {
        "id": "Z1-BMQx4vhkM"
      },
      "id": "Z1-BMQx4vhkM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "model = pickle.load(open(\"model.pkl\", \"rb\"))\n",
        "\n",
        "st.title(\"Week 4: The Airbnb dataset of Amsterdam\")\n",
        "st.markdown(\n",
        "    \"The dataset contains modifications with regards to the original for illustrative & learning purposes\"\n",
        ")\n",
        "\n",
        "st.text(\"This widget can be used by hosts to check their expected tips per listing.\")\n",
        "\n",
        "# review_scores_rating: 0 to 5\n",
        "review_scores_rating = st.slider('What rating is this listing?', 0.00, 5.00, 4.50)\n",
        "# room_type: ['Shared room', 'Private room', 'Hotel room', 'Entire home/apt']\n",
        "room_type = st.radio(\n",
        "    \"What room type do you have?\",\n",
        "    ('Shared room', 'Private room', 'Hotel room', 'Entire home/apt'))\n",
        "# service_cost: ['$0.99', '$4.99', '$2.99', '$10.99']\n",
        "service_cost = st.radio(\n",
        "    \"What room type do you have?\",\n",
        "    ('$0.99', '$4.99', '$2.99', '$10.99'))\n",
        "# instant_bookable: 0, 1\n",
        "instant_bookable = st.radio(\n",
        "    \"Is the listing instantly bookable?\",\n",
        "    (\"True\", \"False\"))\n",
        "instant_bookable = 1 if instant_bookable == \"True\" else 0\n",
        "\n",
        "example = pd.DataFrame({\n",
        "    \"review_scores_rating\": [review_scores_rating],\n",
        "    \"room_type\": [room_type],\n",
        "    \"service_cost\": [service_cost],\n",
        "    \"instant_bookable\": [instant_bookable]\n",
        "    })\n",
        "\n",
        "if st.button('Predict?'):\n",
        "    st.write(\"The model predicts that the tipping category for this listing is:\", model.predict(example)[0])"
      ],
      "metadata": {
        "id": "iu9zLIbXpwmy"
      },
      "id": "iu9zLIbXpwmy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **%%writefile [FILE_NAME].[FILE_EXTENSION]** command let's us save the code written in the cells in your Google Colab instance. Having it saved like that enables us to download it as a file, as seen below:"
      ],
      "metadata": {
        "id": "_AYCGSIhLvnL"
      },
      "id": "_AYCGSIhLvnL"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the file locally\n",
        "files.download('streamlit_app.py')"
      ],
      "metadata": {
        "id": "23mmiMQctwLM"
      },
      "id": "23mmiMQctwLM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "streamlit\n",
        "pandas==1.5.2\n",
        "scikit-learn==1.2.0"
      ],
      "metadata": {
        "id": "9dXqVGYRuEIL"
      },
      "id": "9dXqVGYRuEIL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the file locally\n",
        "files.download('requirements.txt')"
      ],
      "metadata": {
        "id": "3ViZ7akAuM3t"
      },
      "id": "3ViZ7akAuM3t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please verify that you've downloaded three files:\n",
        "- `model.pkl`\n",
        "- `streamlit_app.py`\n",
        "- `requirements.txt`\n",
        "\n",
        "Now let's head over to GitHub and [create an account](https://github.com/signup).\n",
        "\n",
        "Then, since you are logged in [go to GitHub.com](https://github.com) and click on the **+** icon at the top-right corner and select **New repository**.\n",
        "\n",
        "<center>\n",
        "  <img src=https://i.ibb.co/4gkPBCp/Screen-Shot-2022-11-28-at-1-51-02-PM.png width=\"300\" align=\"center\" />\n",
        "</center>\n",
        "<br/>\n",
        "\n",
        "Here you provide:\n",
        "- **Repository name**: Up to you\n",
        "- **License**: Up to you. We recommend **apache-2.0**.\n",
        "\n",
        "- **Public or private?** Public, otherwise you can't host it on [Streamlit Share](https://share.streamlit.io)!\n",
        "\n",
        "<center>\n",
        "  <img src=https://i.ibb.co/0B533dw/Screen-Shot-2022-11-28-at-1-55-14-PM.png width=\"450\" align=\"center\" />\n",
        "</center>\n",
        "<br/>\n",
        "\n",
        "Then upload the three files to this URL below. ***Please modify it before copy-pasting it***:\n",
        "\n",
        "```https://github.com/[YOUR_ACCOUNT_NAME]/[YOUR_REPOSITORY_NAME]/upload/main```\n",
        "\n",
        "<center>\n",
        "  <img src=https://i.ibb.co/jTsrgJw/Screen-Shot-2022-11-28-at-1-58-31-PM.png width=\"500\" align=\"center\" />\n",
        "</center>\n",
        "<br/>\n",
        "\n",
        "Commit directly to the `main` branch, then click **Commit changes**.\n",
        "\n",
        "Next, you have to create an account on [Streamlit Share](https://share.streamlit.io/signup).\n",
        "\n",
        "<center>\n",
        "  <img src=https://i.ibb.co/znFngJc/Screen-Shot-2022-11-28-at-1-59-47-PM.png width=\"500\" align=\"center\" />\n",
        "</center>\n",
        "<br/>\n",
        "\n",
        "It's recommended to click **Continue with GitHub**.\n",
        "\n",
        "Then, select **New app** **>** **Deploy a new app...** **>** **From existing repo**.\n",
        "\n",
        "<center>\n",
        "  <img src=https://i.ibb.co/VQPQzt3/Screen-Shot-2022-11-28-at-2-05-04-PM.png width=\"500\" align=\"center\" />\n",
        "</center>\n",
        "\n",
        "Followed by providing your:\n",
        "\n",
        "```[GITHUB_ACCOUNT_NAME]/[GITHUB_REPOSITORY]```\n",
        "\n",
        "<center>\n",
        "  <img src=https://i.ibb.co/PDSQccD/Screen-Shot-2022-11-28-at-2-10-47-PM.png width=\"500\" align=\"center\" />\n",
        "</center>\n",
        "\n",
        "You will have to wait around 1-5 minutes, then an automatic hyperlink is generated for your new website. An example is this app:\n",
        "\n",
        "```https://[GITHUB_ACCOUNT_NAME]-[GITHUB_REPOSITORY]-[RANDOM_6_LETTER_STRING].streamlit.app/```\n",
        "\n",
        "***Please modify the link before copy-pasting it.***"
      ],
      "metadata": {
        "id": "5STbAwboLzCY"
      },
      "id": "5STbAwboLzCY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# üéâ CONGRATULATIONS!!!\n",
        "\n",
        "Awesome!! You've finished all the Weeks' assignments! Finishing Week 1, 2, 3, and 4 is an amazing feat and requires a lot of hard work and dedication. Please take time to enjoy this!\n",
        "\n",
        "If you have any lingering questions, post them on Slack! As you know, we're always here to help.\n",
        "\n",
        "And if you want any additional challenge questions, check out the bonus extensions below.\n",
        "\n",
        "---\n",
        "\n",
        "## Extensions (Optional)\n",
        "\n",
        "<center>\n",
        "  <img src=https://upload.wikimedia.org/wikipedia/commons/c/c6/Celebration_fireworks.jpg width=\"500\" align=\"center\" />\n",
        "</center>\n",
        "<br/>\n",
        "\n",
        "üéâüéâ Amazing üéâüéâ You completed this week's project! Have you thought about extending this project and try some extensions like:\n",
        "\n",
        "- Using [PCA](https://corise.com/course/intermediate-python-for-data-science/v2/module/unsupervised-learning#corise_clc1r07oc00083b6oy094wn04) on some of the available attributes so that you can simplify the model?\n",
        "- [Create features based on the features you have available](https://corise.com/course/intermediate-python-for-data-science/v2/module/professionalize-moar#corise_clc262ibo00253b6o1omtabr1) and what can be found on the internet?\n",
        "- Perform [hyperparameter tuning](https://corise.com/course/intermediate-python-for-data-science/v2/module/professionalize-moar#corise_clc24tq5a00103b6okrxvknkz) to find the most optimal parameters for your algorithm?\n",
        "- Does it make sense to actually use [other metrics](https://corise.com/course/intermediate-python-for-data-science/v2/module/professionalize-moar#corise_clc262ckm00233b6o546sk268)?\n",
        "- Train the model on [different kinds of Classification algorithms](https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/) from the Scikit-learn toolkit!\n",
        "- ...\n",
        "\n",
        "The possibilities are endless!\n",
        "\n",
        "# Next Up?\n",
        "This was the courses' last week. We've hope you've enjoyed it as much as we did! Thank you for taking this course and working on these projects!"
      ],
      "metadata": {
        "id": "hnwmZSP1L_7M"
      },
      "id": "hnwmZSP1L_7M"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}